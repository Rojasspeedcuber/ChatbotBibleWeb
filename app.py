import os
import streamlit as st
import mercadopago
from decouple import config
from langchain import hub
from langchain_openai import ChatOpenAI
from langchain.agents import create_react_agent, AgentExecutor
from langchain.prompts import PromptTemplate
from langchain_community.utilities.sql_database import SQLDatabase
from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
from payments.page import exibir_link_pagamento
from payments.service import ACCESS_TOKEN

st.set_page_config(page_title='Bible AI', page_icon='biblia.png')


# üîπ Configurando API Key do OpenAI para o Chatbot
os.environ['OPENAI_API_KEY'] = config('OPENAI_API_KEY')

# Fun√ß√£o que exibe a interface de pagamento


def exibir_interface_pagamento():
    st.header("Pagamento Pendentes")
    st.write("Por favor, complete o pagamento para continuar.")
    # Exibe o link para o pagamento
    exibir_link_pagamento()


def verificar_pagamento(preference_id):
    # Configura a chave de acesso do Mercado Pago
    # A chave de acesso do Mercado Pago
    mp = mercadopago.SDK(ACCESS_TOKEN)

    # Verifica o status do pagamento utilizando o ID da prefer√™ncia
    preference = mp.payment().get(preference_id)

    # O status de pagamento pode ser "approved", "pending", "rejected", etc.
    if preference['response']['status'] == 'approved':
        return True  # Pagamento aprovado
    else:
        return False  # Pagamento n√£o aprovado


# Fun√ß√£o principal para o chatbot b√≠blico


def main():
    """Executa a l√≥gica principal do Chatbot B√≠blico."""

    # ID da prefer√™ncia do pagamento, normalmente vindo de uma transa√ß√£o
    preference_id = st.session_state.get('preference_id')

    if not preference_id or not verificar_pagamento(preference_id):
        # Se o pagamento n√£o foi confirmado, exibe a interface de pagamento
        exibir_interface_pagamento()
        return  # N√£o executa o restante do c√≥digo

    # üîπ Se o pagamento foi confirmado, exibe a interface do chatbot
    st.header('Chatbot G√™nesis')

    # üîπ Modelos dispon√≠veis para o Chatbot
    model_options = ['gpt-4', 'gpt-4-turbo', 'gpt-4o-mini', 'gpt-4o']
    bible_options = ['ACF', 'ARA', 'ARC', 'AS21',
                     'KJA', 'NAA', 'NTLH', 'NVI', 'NVT']

    selected_box = st.sidebar.selectbox(
        label='Selecione o modelo LLM', options=model_options)
    selected_bible = st.sidebar.selectbox(
        label='Selecione a vers√£o da base de dados', options=bible_options)

    # üîπ Informa√ß√µes sobre o Chatbot
    st.sidebar.markdown("### Sobre")
    st.sidebar.markdown(
        "Sou o ChatBot G√™nesis. Fui criado pela inspira√ß√£o de Deus na vida de um estudante de Ci√™ncia da Computa√ß√£o. "
        "Utilizo Intelig√™ncia Artificial para ajud√°-lo a conhecer os ensinamentos b√≠blicos."
    )

    st.write("Fa√ßa perguntas sobre a B√≠blia")

    # üîπ Hist√≥rico de mensagens
    if 'messages' not in st.session_state:
        st.session_state['messages'] = []

    # üîπ Input do usu√°rio
    user_question = st.chat_input('O que deseja saber sobre a B√≠blia?')

    # üîπ Configura√ß√£o do modelo e banco de dados
    model = ChatOpenAI(model=selected_box,
                       max_completion_tokens=1000, streaming=True)

    try:
        db = SQLDatabase.from_uri(f'sqlite:///databases/{selected_bible}.db')
    except Exception as e:
        st.error(f"Erro ao conectar ao banco de dados: {e}")
        return

    toolkit = SQLDatabaseToolkit(db=db, llm=model)

    system_message = hub.pull('hwchase17/react')

    agent = create_react_agent(
        llm=model, tools=toolkit.get_tools(), prompt=system_message)
    agent_executor = AgentExecutor(
        agent=agent, tools=toolkit.get_tools(), handle_parsing_errors=True)

    # üîπ Template de prompt para o Chatbot
    prompt = """
        Voc√™ √© um chatbot especializado na B√≠blia Sagrada, capaz de responder perguntas sobre seu conte√∫do, 
        interpreta√ß√£o e contexto hist√≥rico, cultural e espiritual.
        Seu objetivo √© fornecer respostas claras, precisas e baseadas nas escrituras, respeitando todas as tradi√ß√µes crist√£s.
        Responda de forma natural, agrad√°vel e respeitosa. Seja objetivo nas respostas, com 
        informa√ß√µes claras e diretas. Foque em ser natural e humanizado, como um di√°logo comum.
        Use como base a B√≠blia Sagrada disponibilizada no banco de dados.
        Sempre use os vers√≠culos contidos na base de dados para responder as perguntas.
        A resposta final deve ter uma formata√ß√£o amig√°vel (markdown) para visualiza√ß√£o do usu√°rio.
        Responda sempre em portugu√™s brasileiro.
        Pergunta: {q}
    """
    prompt_template = PromptTemplate.from_template(prompt)

    # üîπ Se houver pergunta, processa a resposta
    if user_question:
        for message in st.session_state.messages:
            st.chat_message(message.get('role')).write(message.get('content'))

        st.chat_message('user').write(user_question)
        st.session_state.messages.append(
            {'role': 'user', 'content': user_question})

        with st.spinner('Buscando resposta...'):
            formatted_prompt = prompt_template.format(q=user_question)
            output = agent_executor.invoke({'input': formatted_prompt})
            st.markdown(output.get('output'))


# üîπ Executando o aplicativo
if __name__ == '__main__':
    main()
