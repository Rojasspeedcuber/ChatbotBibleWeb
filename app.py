import os
import streamlit as st
import mercadopago
from fastapi import FastAPI, Request, BackgroundTasks
import requests
import threading
import uvicorn
import logging
from decouple import config
from langchain import hub
from langchain_openai import ChatOpenAI
from langchain.agents import create_react_agent, AgentExecutor
from langchain.prompts import PromptTemplate
from langchain_community.utilities.sql_database import SQLDatabase
from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
from payments.page import exibir_interface_pagamento
from payments.service import verificar_assinatura

st.set_page_config(page_title='Bible AI', page_icon='biblia.png')

# ðŸ”¹ ConfiguraÃ§Ã£o do Logging
logging.basicConfig(filename="webhook.log", level=logging.INFO,
                    format="%(asctime)s - %(message)s")

# ðŸ”¹ ConfiguraÃ§Ã£o da API FastAPI para Webhooks
app = FastAPI()

# ðŸ”¹ ConfiguraÃ§Ã£o do Mercado Pago
ACCESS_TOKEN = config('MERCADO_PAGO_ACCESS_TOKEN')

# ðŸ”¹ Lista para armazenar eventos de Webhooks no Streamlit
if "webhook_events" not in st.session_state:
    st.session_state["webhook_events"] = []


def consultar_pagamento(payment_id):
    """Consulta detalhes do pagamento no Mercado Pago."""
    url = f"https://api.mercadopago.com/v1/payments/{payment_id}"
    headers = {"Authorization": f"Bearer {ACCESS_TOKEN}"}
    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        pagamento = response.json()
        logging.info(f"Pagamento {payment_id} consultado: {pagamento}")
        st.session_state["webhook_events"].append(pagamento)
    else:
        logging.error(
            f"Erro ao consultar pagamento {payment_id}: {response.text}")


@app.post("/webhook")
async def webhook(request: Request, background_tasks: BackgroundTasks):
    """Recebe notificaÃ§Ãµes do Mercado Pago e processa os eventos."""
    data = await request.json()
    logging.info(f"Webhook recebido: {data}")

    if data.get("action") == "payment.created":
        payment_id = data["data"]["id"]
        logging.info(f"Novo pagamento recebido: {payment_id}")
        st.session_state["webhook_events"].append(
            {"status": "Recebido", "id": payment_id})

        # Processa o pagamento em background
        background_tasks.add_task(consultar_pagamento, payment_id)

    return {"status": "ok"}

# ðŸ”¹ Iniciar o servidor FastAPI em uma thread separada


def start_api():
    uvicorn.run(app, host="0.0.0.0", port=8501)


thread = threading.Thread(target=start_api, daemon=True)
thread.start()

# ðŸ”¹ FunÃ§Ã£o principal do Chatbot BÃ­blico


def main():
    """Executa a lÃ³gica principal do Chatbot BÃ­blico."""

    preference_id = st.session_state.get('preapproval_id')

    if not preference_id or not verificar_assinatura(preference_id):
        exibir_interface_pagamento()
        return

    st.header('Chatbot GÃªnesis')

    model_options = ['gpt-4', 'gpt-4-turbo', 'gpt-4o-mini', 'gpt-4o']
    bible_options = ['ACF', 'ARA', 'ARC', 'AS21',
                     'KJA', 'NAA', 'NTLH', 'NVI', 'NVT']

    selected_box = st.sidebar.selectbox(
        label='Selecione o modelo LLM', options=model_options)
    selected_bible = st.sidebar.selectbox(
        label='Selecione a versÃ£o da base de dados', options=bible_options)

    st.sidebar.markdown("### Sobre")
    st.sidebar.markdown(
        "Sou o ChatBot GÃªnesis. Fui criado pela inspiraÃ§Ã£o de Deus na vida de um estudante de CiÃªncia da ComputaÃ§Ã£o. "
        "Utilizo InteligÃªncia Artificial para ajudÃ¡-lo a conhecer os ensinamentos bÃ­blicos."
    )

    st.write("FaÃ§a perguntas sobre a BÃ­blia")

    if 'messages' not in st.session_state:
        st.session_state['messages'] = []

    user_question = st.chat_input('O que deseja saber sobre a BÃ­blia?')

    model = ChatOpenAI(model=selected_box, streaming=True)

    try:
        db = SQLDatabase.from_uri(
            f'sqlite:///databases/{selected_bible}.sqlite')
    except Exception as e:
        st.error(f"Erro ao conectar ao banco de dados: {e}")
        return

    toolkit = SQLDatabaseToolkit(db=db, llm=model)

    system_message = hub.pull('hwchase17/react')

    agent = create_react_agent(
        llm=model, tools=toolkit.get_tools(), prompt=system_message)
    agent_executor = AgentExecutor(
        agent=agent, tools=toolkit.get_tools(), handle_parsing_errors=True)

    prompt = """
        VocÃª Ã© um chatbot especializado na BÃ­blia Sagrada, capaz de responder perguntas sobre seu conteÃºdo, 
        interpretaÃ§Ã£o e contexto histÃ³rico, cultural e espiritual.
        Seu objetivo Ã© fornecer respostas claras, precisas e baseadas nas escrituras, respeitando todas as tradiÃ§Ãµes cristÃ£s.
        Responda de forma natural, agradÃ¡vel e respeitosa. Seja objetivo nas respostas, com 
        informaÃ§Ãµes claras e diretas. Foque em ser natural e humanizado, como um diÃ¡logo comum.
        Use como base a BÃ­blia Sagrada disponibilizada no banco de dados.
        Sempre use os versÃ­culos contidos na base de dados para responder as perguntas.
        A resposta final deve ter uma formataÃ§Ã£o amigÃ¡vel (markdown) para visualizaÃ§Ã£o do usuÃ¡rio.
        Responda sempre em portuguÃªs brasileiro.
        Pergunta: {q}
    """
    prompt_template = PromptTemplate.from_template(prompt)

    if user_question:
        for message in st.session_state.messages:
            st.chat_message(message.get('role')).write(message.get('content'))

        st.chat_message('user').write(user_question)
        st.session_state.messages.append(
            {'role': 'user', 'content': user_question})

        with st.spinner('Buscando resposta...'):
            formatted_prompt = prompt_template.format(q=user_question)
            output = agent_executor.invoke({'input': formatted_prompt})
            st.markdown(output.get('output'))

    # ðŸ”¹ SeÃ§Ã£o para exibir Webhooks recebidos
    st.subheader("ðŸ“‹ Eventos Recebidos do Mercado Pago")
    for event in st.session_state["webhook_events"]:
        st.json(event)


# ðŸ”¹ Executando o aplicativo
if __name__ == '__main__':
    main()
