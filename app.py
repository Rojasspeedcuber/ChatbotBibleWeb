import os
import streamlit as st
from decouple import config
from langchain import hub
from langchain_openai import ChatOpenAI
from langchain.agents import create_react_agent, AgentExecutor
from langchain.prompts import PromptTemplate
from langchain_community.utilities.sql_database import SQLDatabase
from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
from payments.page import exibir_link_pagamento
from payments.service import verificar_pagamento

st.set_page_config(page_title='Bible AI', page_icon='biblia.png')


# ğŸ”¹ Configurando API Key do OpenAI para o Chatbot
os.environ['OPENAI_API_KEY'] = config('OPENAI_API_KEY')

# FunÃ§Ã£o que exibe a interface de pagamento


def exibir_interface_pagamento():
    st.header("Pagamento Pendentes")
    st.write("Por favor, complete o pagamento para continuar.")
    # Exibe o link para o pagamento
    exibir_link_pagamento()

# FunÃ§Ã£o principal para o chatbot bÃ­blico


def main():
    """Executa a lÃ³gica principal do Chatbot BÃ­blico."""

    # ID da preferÃªncia do pagamento, normalmente vindo de uma transaÃ§Ã£o
    preference_id = st.session_state.get('preference_id')

    if not preference_id or not verificar_pagamento(preference_id):
        # Se o pagamento nÃ£o foi confirmado, exibe a interface de pagamento
        exibir_interface_pagamento()
        return  # NÃ£o executa o restante do cÃ³digo

    # ğŸ”¹ Se o pagamento foi confirmado, exibe a interface do chatbot
    st.header('Chatbot GÃªnesis')

    # ğŸ”¹ Modelos disponÃ­veis para o Chatbot
    model_options = ['gpt-4', 'gpt-4-turbo', 'gpt-4o-mini', 'gpt-4o']
    bible_options = ['ACF', 'ARA', 'ARC', 'AS21',
                     'KJA', 'NAA', 'NTLH', 'NVI', 'NVT']

    selected_box = st.sidebar.selectbox(
        label='Selecione o modelo LLM', options=model_options)
    selected_bible = st.sidebar.selectbox(
        label='Selecione a versÃ£o da base de dados', options=bible_options)

    # ğŸ”¹ InformaÃ§Ãµes sobre o Chatbot
    st.sidebar.markdown("### Sobre")
    st.sidebar.markdown(
        "Sou o ChatBot GÃªnesis. Fui criado pela inspiraÃ§Ã£o de Deus na vida de um estudante de CiÃªncia da ComputaÃ§Ã£o. "
        "Utilizo InteligÃªncia Artificial para ajudÃ¡-lo a conhecer os ensinamentos bÃ­blicos."
    )

    st.write("FaÃ§a perguntas sobre a BÃ­blia")

    # ğŸ”¹ HistÃ³rico de mensagens
    if 'messages' not in st.session_state:
        st.session_state['messages'] = []

    # ğŸ”¹ Input do usuÃ¡rio
    user_question = st.chat_input('O que deseja saber sobre a BÃ­blia?')

    # ğŸ”¹ ConfiguraÃ§Ã£o do modelo e banco de dados
    model = ChatOpenAI(model=selected_box,
                       max_completion_tokens=1000, streaming=True)

    try:
        db = SQLDatabase.from_uri(f'sqlite:///databases/{selected_bible}.db')
    except Exception as e:
        st.error(f"Erro ao conectar ao banco de dados: {e}")
        return

    toolkit = SQLDatabaseToolkit(db=db, llm=model)

    system_message = hub.pull('hwchase17/react')

    agent = create_react_agent(
        llm=model, tools=toolkit.get_tools(), prompt=system_message)
    agent_executor = AgentExecutor(
        agent=agent, tools=toolkit.get_tools(), handle_parsing_errors=True)

    # ğŸ”¹ Template de prompt para o Chatbot
    prompt = """
        VocÃª Ã© um chatbot especializado na BÃ­blia Sagrada, capaz de responder perguntas sobre seu conteÃºdo, 
        interpretaÃ§Ã£o e contexto histÃ³rico, cultural e espiritual.
        Seu objetivo Ã© fornecer respostas claras, precisas e baseadas nas escrituras, respeitando todas as tradiÃ§Ãµes cristÃ£s.
        Responda de forma natural, agradÃ¡vel e respeitosa. Seja objetivo nas respostas, com 
        informaÃ§Ãµes claras e diretas. Foque em ser natural e humanizado, como um diÃ¡logo comum.
        Use como base a BÃ­blia Sagrada disponibilizada no banco de dados.
        Sempre use os versÃ­culos contidos na base de dados para responder as perguntas.
        A resposta final deve ter uma formataÃ§Ã£o amigÃ¡vel (markdown) para visualizaÃ§Ã£o do usuÃ¡rio.
        Responda sempre em portuguÃªs brasileiro.
        Pergunta: {q}
    """
    prompt_template = PromptTemplate.from_template(prompt)

    # ğŸ”¹ Se houver pergunta, processa a resposta
    if user_question:
        for message in st.session_state.messages:
            st.chat_message(message.get('role')).write(message.get('content'))

        st.chat_message('user').write(user_question)
        st.session_state.messages.append(
            {'role': 'user', 'content': user_question})

        with st.spinner('Buscando resposta...'):
            formatted_prompt = prompt_template.format(q=user_question)
            output = agent_executor.invoke({'input': formatted_prompt})
            st.markdown(output.get('output'))


# ğŸ”¹ Executando o aplicativo
if __name__ == '__main__':
    main()
